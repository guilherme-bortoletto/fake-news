
-----

# Detec√ß√£o de Fake News com Processamento em Larga Escala Utilizando MongoDB Atlas e Python

## Conceito do projeto

O projeto tem como foco o desenvolvimento de um pipeline completo para a detec√ß√£o autom√°tica de fake news, integrando tecnologias de armazenamento e processamento de dados. Utilizando o **MongoDB Atlas** como banco de dados NoSQL e a biblioteca **Pymongo** em um ambiente **Databricks** para a an√°lise e processamento, o sistema √© capaz de armazenar, transformar e analisar milhares de not√≠cias jornal√≠sticas.

Nosso objetivo √© demonstrar a aplica√ß√£o de tecnologias NoSQL e frameworks de processamento para:

  * Armazenar de forma flex√≠vel e escal√°vel um volume significativo de not√≠cias.
  * Processar dados textuais em larga escala utilizando t√©cnicas de NLP (*Natural Language Processing*).
  * Treinar e avaliar um modelo de *machine learning* para classificar not√≠cias.
  * Avaliar a viabilidade da arquitetura proposta no contexto de aplica√ß√µes robustas.
  * Identificar padr√µes lingu√≠sticos, como as palavras mais frequentes em textos de *fake news*.

## Pr√©-requisitos e recursos utilizados

**Linguagens e Bibliotecas:**

  * **Python 3.x**
  * **Pymongo:** Para intera√ß√£o direta com o MongoDB Atlas.
  * **Pandas:** Para manipula√ß√£o e an√°lise de dados.
  * **Scikit-learn:** Para pr√©-processamento, vetoriza√ß√£o (TF-IDF) e treinamento do modelos.
  * **NLTK:** Para processamento de linguagem natural (stopwords).
  * **Matplotlib / Seaborn:** Para visualiza√ß√£o de dados e gera√ß√£o de gr√°ficos.

**Infraestrutura e Plataformas:**

  * **MongoDB Atlas:** Banco de dados NoSQL na nuvem para armazenamento dos artigos.
  * **Databricks:** Plataforma utilizada para a execu√ß√£o dos notebooks de an√°lise em Python.

**Fonte de Dados:**

  * **Fake and Real News Dataset ‚Äì Kaggle:** O conjunto de dados original, contendo aproximadamente 44.000 artigos, foi utilizado como base.
      * Dispon√≠vel em: [Fake and Real News Dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)

## Passo a passo

O projeto foi estruturado seguindo um pipeline claro de processamento de dados, desde a coleta at√© a an√°lise e avalia√ß√£o do modelo.

1.  **Obten√ß√£o dos Dados**: Download dos arquivos `Fake.csv` e `True.csv` a partir da fonte de dados no Kaggle.
2.  **Ingest√£o no Banco de Dados**: Cada not√≠cia foi convertida para o formato JSON e inserida em uma *collection* espec√≠fica (`Fake` ou `Real`) no cluster do MongoDB Atlas.
3.  **Conex√£o e Leitura**: Utilizando um notebook no ambiente Databricks, estabelecemos a conex√£o com o MongoDB Atlas via `Pymongo` e carregamos os dados para an√°lise.
4.  **Processamento e Vetoriza√ß√£o**: Os textos foram processados com t√©cnicas de NLP (limpeza, tokeniza√ß√£o, remo√ß√£o de stopwords) e transformados em vetores num√©ricos com a t√©cnica **TF-IDF**.
5.  **Treinamento do Modelo**: Um modelo de classifica√ß√£o de **Regress√£o Log√≠stica** foi treinado com os dados vetorizados para distinguir entre not√≠cias falsas e verdadeiras.
6.  **An√°lise e Avalia√ß√£o**: Foram realizadas an√°lises explorat√≥rias para identificar padr√µes lingu√≠sticos (palavras mais frequentes, n-gramas, an√°lise de sentimento) e o modelo foi avaliado quanto √† sua acur√°cia e outras m√©tricas de desempenho.

### Fluxograma do Pipeline

```mermaid
graph TD
    subgraph "Origem dos Dados"
        A["Kaggle
        (Arquivos CSV)"];
    end

    subgraph "Banco de Dados (Nuvem)"
        B["MongoDB Atlas"];
        subgraph "Collections"
            B1["Collection: Fake"];
            B2["Collection: Real"];
        end
        B -.-> B1;
        B -.-> B2;
    end
    
    subgraph "Ambiente de An√°lise (Databricks)"
        C["Notebook Python"];
        D["Processamento e Vetoriza√ß√£o
        (scikit-learn e TF-IDF)"];
        E["Treinamento do Modelo
        (Regress√£o Log√≠stica)"];
        F["An√°lise Textual Explorat√≥ria
        (N-gramas e Sentimento)"];
        G{{Modelo Classificador}};
        H{{Resultados e Visualiza√ß√µes}};
    end

    A -- "Passo 1: Obten√ß√£o e Inser√ß√£o" --> B;
    B -- "Passo 2: Leitura com Pymongo" --> C;
    C -- "Passo 3: Processamento" --> D;
    D -- "Passo 4a: Treinamento" --> E;
    D -- "Passo 4b: An√°lise" --> F;
    E -- "Passo 5: Gera Resultado" --> G;
    F -- "Passo 6: Gera Resultado" --> H;
```

## Instala√ß√£o

Para replicar o ambiente do projeto, siga os passos abaixo:

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/guilherme-bortoletto/fake-news.git
    cd fake-news
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install pymongo pandas scikit-learn nltk matplotlib seaborn jupyter
    ```
4.  **Configure o MongoDB Atlas:**
      * Crie um cluster gratuito no [MongoDB Atlas](https://www.mongodb.com/cloud/atlas).
      * Crie um banco de dados (ex: `Fake_and_Real`) e duas collections (ex: `Fake` e `Real`).
      * Obtenha a **URI de conex√£o** e substitua no script de an√°lise.
5.  **Carregue os dados:** Execute um script para ler os arquivos `Fake.csv` e `True.csv` e inseri-los nas *collections* correspondentes no MongoDB Atlas.

## Execu√ß√£o

1.  Abra o notebook de an√°lise (arquivo `.ipynb`) no ambiente de sua prefer√™ncia (Jupyter, VS Code ou Databricks).
2.  Assegure-se de que a URI de conex√£o com o MongoDB Atlas est√° corretamente configurada no c√≥digo:
    ```python
    from pymongo import MongoClient

    # Substitua pela sua URI de conex√£o
    conn_uri = "mongodb+srv://<user>:<password>@cluster.mongodb.net/?retryWrites=true&w=majority"
    client = MongoClient(conn_uri)
    db = client["Fake_and_Real"]
    ```
3.  Execute as c√©lulas do notebook sequencialmente para realizar a leitura dos dados, o pr√©-processamento, o treinamento do modelo e a visualiza√ß√£o dos resultados.

## Bugs/problemas conhecidos

  * **Mudan√ßa de Estrat√©gia de Processamento:** O plano inicial era utilizar **PySpark** no Databricks para o processamento distribu√≠do. Contudo, devido a limita√ß√µes da vers√£o **Databricks Community Edition**, que removeu o acesso a clusters computacionais em seu plano gratuito, o conector `spark-mongodb` tornou-se invi√°vel. Como solu√ß√£o, o projeto foi adaptado para usar a biblioteca **Pymongo** para intera√ß√£o direta com o MongoDB, mantendo a integridade do pipeline, embora sem o processamento distribu√≠do do Spark.

## Autores

  * **Vinicius Silva Castro** ‚Äì 802138
  * **Guilherme Campos Bortoletto** ‚Äì 801477


--
## An√°lise Detalhada e Resultados

Nesta fase, o desempenho do modelo de classifica√ß√£o foi rigorosamente avaliado e uma an√°lise quantitativa aprofundada foi realizada para extrair padr√µes lingu√≠sticos e estat√≠sticos dos textos.

### Avalia√ß√£o de Desempenho do Modelo (Regress√£o Log√≠stica)

Para este projeto, foram testados diferentes modelos de classifica√ß√£o para a tarefa de detec√ß√£o de fake news. Dentre as abordagens avaliadas, o modelo de Regress√£o Log√≠stica foi o que apresentou a melhor performance, demonstrando uma capacidade excepcional de distinguir entre os textos com uma acur√°cia de 99% no conjunto de teste, al√©m de m√©tricas de precis√£o e recall quase perfeitas para ambas as classes.

#### Relat√≥rio de Classifica√ß√£o:

```
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      4733
           1       0.99      0.99      0.99      4247

    accuracy                           0.99      8980
   macro avg       0.99      0.99      0.99      8980
weighted avg       0.99      0.99      0.99      8980
```

#### Matriz de Confus√£o:

A matriz de confus√£o abaixo detalha os acertos e erros do modelo, onde a classe `0` representa not√≠cias falsas e a `1`, not√≠cias verdadeiras.

```
[[4684   49]
 [  51 4196]]
```

|                         | **Previsto: Falso (0)** | **Previsto: Real (1)** |
|:------------------------|:-----------------------:|:------------------------:|
| **Verdadeiro: Falso (0)** | 4684 ‚úÖ (Verdadeiro Negativo - TN) | 49 ‚ùå (Falso Positivo - FP) |
| **Verdadeiro: Real (1)** | 51 ‚ùå (Falso Negativo - FN)       | 4196 ‚úÖ (Verdadeiro Positivo - TP) |

##### üß† Interpreta√ß√£o:

  - O modelo classificou corretamente **4684** not√≠cias falsas e **4196** not√≠cias verdadeiras.
  - Os erros foram m√≠nimos: apenas **49** not√≠cias verdadeiras foram classificadas como falsas (falsos positivos) e **51** not√≠cias falsas foram consideradas verdadeiras (falsos negativos).
  - Essa alta taxa de acerto confirma que o modelo de Regress√£o Log√≠stica √© extremamente eficaz e robusto para este problema.

### An√°lise Quantitativa e Lingu√≠stica

#### 1\. Palavras Mais Frequentes por Classe

A an√°lise das palavras mais frequentes revela padr√µes lingu√≠sticos distintos. Nas fake news, termos como "hillary", "clinton", "obama" e "trump" dominam o vocabul√°rio, indicando um forte vi√©s pol√≠tico e a utiliza√ß√£o de figuras polarizadoras. Palavras como "us", "president" e "people" sugerem um foco em temas nacionais, frequentemente associados a teorias da conspira√ß√£o. Al√©m disso, o uso de termos como "would", "even" e "like" aponta para um tom mais hipot√©tico e emocional.

Por outro lado, as not√≠cias reais apresentam um perfil mais neutro e factual. Termos como "washington", "united", "states" e "government" refletem uma abordagem mais institucional. Express√µes como "told", "could" e "house" indicam um discurso mais descritivo e menos carregado de emo√ß√£o. Embora "trump" e "president" tamb√©m apare√ßam, seu uso √© menos dominante e mais contextualizado.

#### 2\. Nuvem de Palavras (Word Cloud)

As nuvens de palavras refor√ßam e complementam os padr√µes identificados. Na nuvem das **fake news**, destacam-se visualmente termos como "Trump", "Hillary" e "Clinton", confirmando o foco em figuras pol√≠ticas. A presen√ßa marcante desses nomes sugere que as fake news se aproveitam de sua notoriedade para atrair aten√ß√£o. Em contraste, a nuvem das **not√≠cias reais** apresenta um vocabul√°rio mais diversificado, com termos como "Washington", "United", "States" e "government" predominando, o que reflete uma abordagem mais institucional e factual.

#### 3\. Distribui√ß√£o de Tamanho dos Textos

A an√°lise da distribui√ß√£o do tamanho dos textos (em caracteres) mostra que a maioria se concentra na faixa de 0 a 5.000 caracteres. Observa-se um pico em torno de 2.000 caracteres, com a curva de textos falsos (`label 0`) ligeiramente mais alta nessa regi√£o, o que sugere que esses textos tendem a ser um pouco mais curtos. Apesar dessas diferen√ßas sutis, as distribui√ß√µes s√£o bastante semelhantes, indicando que o tamanho, isoladamente, pode n√£o ser um fator decisivo para a diferencia√ß√£o.

#### 4\. Frequ√™ncia de Bigramas (Pares de Palavras)

A an√°lise de bigramas revela diferen√ßas marcantes. Nos conte√∫dos falsos, observa-se uma predomin√¢ncia de combina√ß√µes envolvendo figuras pol√≠ticas, como "donald trump" e "hillary clinton". Este padr√£o sugere uma estrat√©gia de associar a desinforma√ß√£o a personalidades j√° carregadas de significado pol√≠tico. Em contraste, as not√≠cias reais apresentam uma estrutura mais convencional. Bigramas como "trump said" seguem o padr√£o profissional de atribui√ß√£o de fontes, enquanto combina√ß√µes como "prime minister" e "north korea" demonstram uma cobertura mais ampla de temas internacionais.

#### 5\. Frequ√™ncia de Trigramas (Trios de Palavras)

A an√°lise de trigramas revela padr√µes ainda mais distintos. Nos conte√∫dos falsos, destacam-se estruturas que combinam termos institucionais com alega√ß√µes n√£o verificadas, como "century wire says". A presen√ßa marcante de "president barack obama" e "president donald trump" indica a apropria√ß√£o de cargos para dar apar√™ncia de legitimidade. Not√≠cias reais, por outro lado, apresentam trigramas que refletem pr√°ticas jornal√≠sticas convencionais, como "white house said" e "secretary state rex", demonstrando preocupa√ß√£o com a atribui√ß√£o precisa de declara√ß√µes.

#### 6\. An√°lise de Sentimento

O gr√°fico de boxplot mostra a distribui√ß√£o dos escores de sentimento, variando de -1.0 (negativo) a +1.0 (positivo). As medianas de ambas as classes est√£o pr√≥ximas de 0.0, sugerindo que os textos, em m√©dia, tendem ao sentimento neutro. No entanto, a classe **Fake** (vermelha) exibe uma dispers√£o ligeiramente maior de sentimentos negativos, com alguns outliers em extremos negativos. Isso pode indicar que textos falsos, em certos casos, carregam uma carga emocional mais negativa, o que pode ser uma feature √∫til para a detec√ß√£o.

#### 7\. An√°lise de Features de Comprimento

Os dados revelam padr√µes sutis na estrutura textual. Em m√©dia, os textos classificados como fake news apresentam uma extens√£o ligeiramente maior, tanto em caracteres quanto em palavras. Esses resultados sugerem que conte√∫dos falsos podem adotar estrat√©gias de maior detalhamento ou repeti√ß√£o para refor√ßar suas narrativas.

| Classe | M√©dia de Caracteres (text\_length) | M√©dia de Palavras (word\_count) |
|:---|:---:|:---:|
| **Fake News (0)** | 1740.86 | 230.74 |
| **Not√≠cias Reais (1)** | 1719.16 | 226.66 |

## Conclus√£o

Este trabalho realizou uma an√°lise detalhada de fake news utilizando uma infraestrutura tecnol√≥gica eficiente composta por MongoDB Atlas, PyMongo e Databricks. Essa combina√ß√£o mostrou-se ideal para todo o fluxo de trabalho, desde o armazenamento flex√≠vel dos dados em formato JSON at√© a execu√ß√£o otimizada das an√°lises textuais e estat√≠sticas.

A arquitetura provou-se escal√°vel e flex√≠vel, permitindo adaptar a estrutura dos dados conforme novas necessidades surgiam. A an√°lise lingu√≠stica forneceu evid√™ncias robustas sobre as assinaturas da desinforma√ß√£o, como o uso excessivo de nomes de figuras p√∫blicas, tom emocional e aus√™ncia de fontes atribu√≠das. O modelo preditivo, baseado nessas caracter√≠sticas, alcan√ßou um desempenho excelente, validando a efic√°cia da abordagem.

Os resultados sugerem que a combina√ß√£o dessas features pode servir como base para sistemas de classifica√ß√£o autom√°tica mais sofisticados. Para o p√∫blico geral, estes achados oferecem indicadores pr√°ticos para a identifica√ß√£o de conte√∫do suspeito. Como pr√≥ximos passos, sugere-se a integra√ß√£o dessas descobertas em modelos mais avan√ßados e a cria√ß√£o de materiais educativos que traduzam esses padr√µes em orienta√ß√µes acess√≠veis.

## Demais anota√ß√µes e refer√™ncias

1.  **MongoDB Atlas e Integra√ß√£o com Python (PyMongo)**
    MongoDB, Inc. (2024). *A Guide to Connect Databricks and MongoDB Atlas using Python API*. CloudThat.
    Dispon√≠vel em: [https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api](https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api)

2.  **Databricks e Processamento de Dados com MongoDB Atlas**
    Raisinghani, A. (2024). *Utilizing PySpark to Connect MongoDB Atlas with Azure Databricks*. MongoDB Developer Center.
    Dispon√≠vel em: [https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo](https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo)

3.  **Documenta√ß√£o Oficial do PyMongo**
    MongoDB, Inc. (2025). *PyMongo Documentation*.
    Dispon√≠vel em: [https://pymongo.readthedocs.io](https://pymongo.readthedocs.io)

4.  **Documenta√ß√£o Oficial do Databricks**
    Databricks, Inc. (2025). *Databricks Documentation*.
    Dispon√≠vel em: [https://docs.databricks.com](https://docs.databricks.com)