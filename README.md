
-----

# Detec√ß√£o de Fake News com Processamento em Larga Escala Utilizando MongoDB Atlas e Python

## Conceito do projeto

O projeto tem como foco o desenvolvimento de um pipeline completo para a detec√ß√£o autom√°tica de fake news, integrando tecnologias de armazenamento e processamento de dados. Utilizando o **MongoDB Atlas** como banco de dados NoSQL e a biblioteca **Pymongo** em um ambiente **Databricks** para a an√°lise e processamento, o sistema √© capaz de armazenar, transformar e analisar milhares de not√≠cias jornal√≠sticas.

Nosso objetivo √© demonstrar a aplica√ß√£o de tecnologias NoSQL e frameworks de processamento para:

  * Armazenar de forma flex√≠vel e escal√°vel um volume significativo de not√≠cias.
  * Processar dados textuais em larga escala utilizando t√©cnicas de NLP (*Natural Language Processing*).
  * Treinar e avaliar um modelo de *machine learning* para classificar not√≠cias.
  * Avaliar a viabilidade da arquitetura proposta no contexto de aplica√ß√µes robustas.
  * Identificar padr√µes lingu√≠sticos, como as palavras mais frequentes em textos de *fake news*.

## Pr√©-requisitos e recursos utilizados

**Linguagens e Bibliotecas:**

  * **Python 3.x**
  * **Pymongo:** Para intera√ß√£o direta com o MongoDB Atlas.
  * **Pandas:** Para manipula√ß√£o e an√°lise de dados.
  * **Scikit-learn:** Para pr√©-processamento, vetoriza√ß√£o (TF-IDF) e treinamento do modelos.
  * **NLTK:** Para processamento de linguagem natural (stopwords).
  * **Matplotlib / Seaborn:** Para visualiza√ß√£o de dados e gera√ß√£o de gr√°ficos.

**Infraestrutura e Plataformas:**

  * **MongoDB Atlas:** Banco de dados NoSQL na nuvem para armazenamento dos artigos.
  * **Databricks:** Plataforma utilizada para a execu√ß√£o dos notebooks de an√°lise em Python.

**Fonte de Dados:**

  * **Fake and Real News Dataset ‚Äì Kaggle:** O conjunto de dados original, contendo aproximadamente 44.000 artigos, foi utilizado como base.
      * Dispon√≠vel em: [Fake and Real News Dataset](https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset)

## Passo a passo

O projeto foi estruturado seguindo um pipeline claro de processamento de dados, desde a coleta at√© a an√°lise e avalia√ß√£o do modelo.

1.  **Obten√ß√£o dos Dados**: Download dos arquivos `Fake.csv` e `True.csv` a partir da fonte de dados no Kaggle.
2.  **Ingest√£o no Banco de Dados**: Cada not√≠cia foi convertida para o formato JSON e inserida em uma *collection* espec√≠fica (`Fake` ou `Real`) no cluster do MongoDB Atlas.
3.  **Conex√£o e Leitura**: Utilizando um notebook no ambiente Databricks, estabelecemos a conex√£o com o MongoDB Atlas via `Pymongo` e carregamos os dados para an√°lise.
4.  **Processamento e Vetoriza√ß√£o**: Os textos foram processados com t√©cnicas de NLP (limpeza, tokeniza√ß√£o, remo√ß√£o de stopwords) e transformados em vetores num√©ricos com a t√©cnica **TF-IDF**.
5.  **Treinamento do Modelo**: Um modelo de classifica√ß√£o de **Regress√£o Log√≠stica** foi treinado com os dados vetorizados para distinguir entre not√≠cias falsas e verdadeiras.
6.  **An√°lise e Avalia√ß√£o**: Foram realizadas an√°lises explorat√≥rias para identificar padr√µes lingu√≠sticos (palavras mais frequentes, n-gramas, an√°lise de sentimento) e o modelo foi avaliado quanto √† sua acur√°cia e outras m√©tricas de desempenho.

### Fluxograma do Pipeline

```mermaid
graph TD
    subgraph "Origem dos Dados"
        A["Kaggle
        (Arquivos CSV)"];
    end

    subgraph "Banco de Dados (Nuvem)"
        B["MongoDB Atlas"];
        subgraph "Collections"
            B1["Collection: Fake"];
            B2["Collection: Real"];
        end
        B -.-> B1;
        B -.-> B2;
    end
    
    subgraph "Ambiente de An√°lise (Databricks)"
        C["Notebook Python"];
        D["Processamento e Vetoriza√ß√£o
        (scikit-learn e TF-IDF)"];
        E["Treinamento do Modelo
        (Regress√£o Log√≠stica)"];
        F["An√°lise Textual Explorat√≥ria
        (N-gramas e Sentimento)"];
        G{{Modelo Classificador}};
        H{{Resultados e Visualiza√ß√µes}};
    end

    A -- "Passo 1: Obten√ß√£o e Inser√ß√£o" --> B;
    B -- "Passo 2: Leitura com Pymongo" --> C;
    C -- "Passo 3: Processamento" --> D;
    D -- "Passo 4a: Treinamento" --> E;
    D -- "Passo 4b: An√°lise" --> F;
    E -- "Passo 5: Gera Resultado" --> G;
    F -- "Passo 6: Gera Resultado" --> H;
```

## Instala√ß√£o

Para replicar o ambiente do projeto, siga os passos abaixo:

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/guilherme-bortoletto/fake-news.git
    cd fake-news
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install pymongo pandas scikit-learn nltk matplotlib seaborn jupyter
    ```
4.  **Configure o MongoDB Atlas:**
      * Crie um cluster gratuito no [MongoDB Atlas](https://www.mongodb.com/cloud/atlas).
      * Crie um banco de dados (ex: `Fake_and_Real`) e duas collections (ex: `Fake` e `Real`).
      * Obtenha a **URI de conex√£o** e substitua no script de an√°lise.
5.  **Carregue os dados:** Execute um script para ler os arquivos `Fake.csv` e `True.csv` e inseri-los nas *collections* correspondentes no MongoDB Atlas.

## Execu√ß√£o

1.  Abra o notebook de an√°lise (arquivo `.ipynb`) no ambiente de sua prefer√™ncia (Jupyter, VS Code ou Databricks).
2.  Assegure-se de que a URI de conex√£o com o MongoDB Atlas est√° corretamente configurada no c√≥digo:
    ```python
    from pymongo import MongoClient

    # Substitua pela sua URI de conex√£o
    conn_uri = "mongodb+srv://<user>:<password>@cluster.mongodb.net/?retryWrites=true&w=majority"
    client = MongoClient(conn_uri)
    db = client["Fake_and_Real"]
    ```
3.  Execute as c√©lulas do notebook sequencialmente para realizar a leitura dos dados, o pr√©-processamento, o treinamento do modelo e a visualiza√ß√£o dos resultados.

## Bugs/problemas conhecidos

  * **Mudan√ßa de Estrat√©gia de Processamento:** O plano inicial era utilizar **PySpark** no Databricks para o processamento distribu√≠do. Contudo, devido a limita√ß√µes da vers√£o **Databricks Community Edition**, que removeu o acesso a clusters computacionais em seu plano gratuito, o conector `spark-mongodb` tornou-se invi√°vel. Como solu√ß√£o, o projeto foi adaptado para usar a biblioteca **Pymongo** para intera√ß√£o direta com o MongoDB, mantendo a integridade do pipeline, embora sem o processamento distribu√≠do do Spark.

## Autores

  * **Vinicius Silva Castro** ‚Äì 802138
  * **Guilherme Campos Bortoletto** ‚Äì 801477


--
## An√°lise Detalhada e Resultados

Nesta fase, o desempenho do modelo de classifica√ß√£o foi rigorosamente avaliado e uma an√°lise quantitativa aprofundada foi realizada para extrair padr√µes lingu√≠sticos e estat√≠sticos dos textos.

### Avalia√ß√£o de Desempenho do Modelo (Regress√£o Log√≠stica)

Para este projeto, foram testados diferentes modelos de classifica√ß√£o para a tarefa de detec√ß√£o de fake news. Dentre as abordagens avaliadas, o modelo de Regress√£o Log√≠stica foi o que apresentou a melhor performance, demonstrando uma capacidade excepcional de distinguir entre os textos com uma acur√°cia de 99% no conjunto de teste, al√©m de m√©tricas de precis√£o e recall quase perfeitas para ambas as classes.

#### Relat√≥rio de Classifica√ß√£o:

```
              precision    recall  f1-score   support

           0       0.99      0.99      0.99      4733
           1       0.99      0.99      0.99      4247

    accuracy                           0.99      8980
   macro avg       0.99      0.99      0.99      8980
weighted avg       0.99      0.99      0.99      8980
```

#### Matriz de Confus√£o:

A matriz de confus√£o abaixo detalha os acertos e erros do modelo, onde a classe `0` representa not√≠cias falsas e a `1`, not√≠cias verdadeiras.

```
[[4684   49]
 [  51 4196]]
```

|                         | **Previsto: Falso (0)** | **Previsto: Real (1)** |
|:------------------------|:-----------------------:|:------------------------:|
| **Verdadeiro: Falso (0)** | 4684 ‚úÖ (Verdadeiro Negativo - TN) | 49 ‚ùå (Falso Positivo - FP) |
| **Verdadeiro: Real (1)** | 51 ‚ùå (Falso Negativo - FN)       | 4196 ‚úÖ (Verdadeiro Positivo - TP) |

##### üß† Interpreta√ß√£o:

  - O modelo classificou corretamente **4684** not√≠cias falsas e **4196** not√≠cias verdadeiras.
  - Os erros foram m√≠nimos: apenas **49** not√≠cias verdadeiras foram classificadas como falsas (falsos positivos) e **51** not√≠cias falsas foram consideradas verdadeiras (falsos negativos).
  - Essa alta taxa de acerto confirma que o modelo de Regress√£o Log√≠stica √© extremamente eficaz e robusto para este problema.

### **An√°lise Quantitativa e Lingu√≠stica**

A an√°lise explorat√≥ria dos dados revelou diferen√ßas sistem√°ticas e marcantes entre os padr√µes lingu√≠sticos de not√≠cias falsas e verdadeiras. Estes padr√µes, quando examinados em conjunto, formam uma "impress√£o digital" que permite a um modelo de machine learning classificar os textos com alta precis√£o.

#### 1. Palavras Mais Frequentes por Classe

A an√°lise das palavras mais frequentes exp√µe uma diferen√ßa fundamental na estrat√©gia de comunica√ß√£o de cada tipo de conte√∫do. As not√≠cias falsas s√£o dominadas por termos que evocam forte vi√©s pol√≠tico e personalismo, como "hillary", "clinton", "obama" e "trump". A alta frequ√™ncia desses nomes pr√≥prios sugere uma t√°tica focada em polariza√ß√£o e resposta emocional, explorando figuras p√∫blicas como √¢ncoras para a narrativa. Palavras como "us", "president" e "people" refor√ßam um foco em temas nacionais, muitas vezes no contexto de teorias da conspira√ß√£o ou desinforma√ß√£o estrat√©gica.

Em contrapartida, as not√≠cias reais apresentam um perfil lingu√≠stico mais neutro, factual e institucional. Termos como "washington", "united", "states" e "government" refletem um foco em processos, institui√ß√µes e locais, em vez de personalidades. Express√µes como "told", "could" e "house" indicam um discurso mais descritivo e cauteloso, caracter√≠stico do jornalismo profissional que visa relatar eventos em vez de provocar rea√ß√µes. Essa clara distin√ß√£o lexical √© uma das features mais poderosas para o modelo de classifica√ß√£o.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/most_frequence_words.png)

#### 2. Nuvem de Palavras (Word Cloud)

As nuvens de palavras refor√ßam e complementam visualmente os padr√µes identificados na an√°lise de frequ√™ncia. Na nuvem das **fake news**, o tamanho proeminente de nomes como "Trump", "Hillary" e "Clinton" confirma o foco avassalador em figuras pol√≠ticas. A presen√ßa marcante desses nomes sugere que a notoriedade dessas personalidades √© usada como um atalho para gerar engajamento e credibilidade fabricada.

Em n√≠tido contraste, a nuvem de palavras das **not√≠cias reais** exibe um vocabul√°rio mais distribu√≠do e diversificado. Termos como "Washington", "United States", "government" e "House" s√£o predominantes, refletindo uma abordagem mais s√≥bria e centrada em fatos institucionais. A visualiza√ß√£o mostra que, enquanto as fake news giram em torno de poucos indiv√≠duos, as not√≠cias reais cobrem um espectro mais amplo de t√≥picos, o que √© um indicador de pr√°ticas jornal√≠sticas mais equilibradas.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/word_cloud.png)

#### 3. Distribui√ß√£o de Tamanho dos Textos

A an√°lise da distribui√ß√£o do comprimento dos textos (em n√∫mero de caracteres) revela que a maioria dos artigos, em ambas as classes, se concentra na faixa de 0 a 5.000 caracteres. Existe um pico not√°vel em torno de 2.000 caracteres, onde a curva de not√≠cias falsas (label 0) √© ligeiramente mais alta, sugerindo uma tend√™ncia para textos um pouco mais curtos nessa categoria. Uma hip√≥tese para esse padr√£o √© que a desinforma√ß√£o √© frequentemente otimizada para consumo r√°pido em plataformas de m√≠dia social. Apesar dessa sutil diferen√ßa, as distribui√ß√µes gerais s√£o bastante semelhantes, indicando que o tamanho do texto, por si s√≥, √© uma feature de baixo poder preditivo em compara√ß√£o com as caracter√≠sticas lexicais.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/text_length.png)

#### 4. Frequ√™ncia de Bigramas (Pares de Palavras)

A an√°lise de bigramas revela diferen√ßas marcantes na constru√ß√£o frasal. Os conte√∫dos falsos s√£o dominados por combina√ß√µes que nomeiam figuras pol√≠ticas, como "donald trump" e "hillary clinton". Esse padr√£o sugere uma estrat√©gia deliberada de vincular a desinforma√ß√£o a personalidades com forte carga pol√≠tica, explorando vieses cognitivos preexistentes no p√∫blico.

Em contraste, as not√≠cias reais apresentam uma estrutura mais convencional e profissional. Bigramas como "trump said" e "said statement" refletem a pr√°tica jornal√≠stica de atribui√ß√£o clara de fontes. Da mesma forma, pares como "prime minister" e "north korea" demonstram uma cobertura mais ampla de temas internacionais. Essa diferen√ßa √© crucial: as fake news focam em *quem* √© o assunto, enquanto as not√≠cias reais focam em *quem disse o qu√™*, um pilar da credibilidade jornal√≠stica.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/bigrama.png)

#### 5. Frequ√™ncia de Trigramas (Trios de Palavras)

Os trigramas revelam padr√µes ainda mais sofisticados de credibilidade e atribui√ß√£o. Nas not√≠cias falsas, destacam-se estruturas que tentam fabricar autoridade, como "century wire says" (uma fonte de baixa reputa√ß√£o) ou "president donald trump" usado de forma isolada para dar peso a uma alega√ß√£o.

Por outro lado, as not√≠cias reais cont√™m trigramas que refletem pr√°ticas editoriais rigorosas, como "white house said" e "secretary state rex", que demonstram uma preocupa√ß√£o com a atribui√ß√£o precisa de declara√ß√µes a fontes reconhecidas. A variedade de combina√ß√µes, incluindo nomes de oficiais e institui√ß√µes, mostra uma cobertura mais contextualizada. Enquanto as fake news se apropriam de nomes para dar uma falsa impress√£o de legitimidade, as not√≠cias reais os utilizam para construir uma narrativa factual e verific√°vel.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/trigrama.png)

#### 6. An√°lise de Sentimento

O gr√°fico de boxplot da polaridade de sentimento (onde -1.0 √© negativo e +1.0 √© positivo) mostra que as medianas de ambas as classes est√£o pr√≥ximas de 0.0, indicando um tom majoritariamente neutro. Contudo, a an√°lise da dispers√£o revela um insight importante: a classe **Fake** (vermelha) exibe uma variabilidade significativamente maior, com mais outliers nos extremos negativo e positivo. Isso sugere que as not√≠cias falsas recorrem com mais frequ√™ncia a uma linguagem carregada de emo√ß√£o (tanto positiva quanto negativa) para gerar engajamento, indigna√ß√£o ou euforia. As not√≠cias reais, embora possam cobrir eventos com carga emocional, tendem a manter uma distribui√ß√£o de sentimento mais contida e pr√≥xima da neutralidade, refletindo um compromisso com a objetividade.
![Imagem](https://github.com/guilherme-bortoletto/fake-news/edit/main/img/sentimento.png)

#### 7. An√°lise de Features de Comprimento

Os dados revelam padr√µes sutis, por√©m consistentes, na estrutura textual. Em m√©dia, os textos classificados como fake news s√£o ligeiramente mais longos, tanto em caracteres (1740.86 vs. 1719.16) quanto em palavras (230.74 vs. 226.66). Esse achado, embora com uma diferen√ßa pequena, pode contradizer a percep√ß√£o de que a desinforma√ß√£o √© sempre superficial. Uma hip√≥tese √© que alguns conte√∫dos falsos utilizam uma linguagem mais prolixa e com excesso de detalhes para criar uma falsa aura de profundidade e autoridade, tentando sobrecarregar o leitor com informa√ß√µes para parecerem mais cr√≠veis.

| Classe | M√©dia de Caracteres | M√©dia de Palavras |
| :--- | :---: | :---: |
| **Fake News (0)** | 1740.86 | 230.74 |
| **Not√≠cias Reais (1)** | 1719.16 | 226.66 |

## Conclus√£o

Este trabalho realizou uma an√°lise detalhada de fake news utilizando uma infraestrutura tecnol√≥gica eficiente composta por MongoDB Atlas, PyMongo e Databricks. Essa combina√ß√£o mostrou-se ideal para todo o fluxo de trabalho, desde o armazenamento flex√≠vel dos dados em formato JSON at√© a execu√ß√£o otimizada das an√°lises textuais e estat√≠sticas.

A arquitetura provou-se escal√°vel e flex√≠vel, permitindo adaptar a estrutura dos dados conforme novas necessidades surgiam. A an√°lise lingu√≠stica forneceu evid√™ncias robustas sobre as assinaturas da desinforma√ß√£o, como o uso excessivo de nomes de figuras p√∫blicas, tom emocional e aus√™ncia de fontes atribu√≠das. O modelo preditivo, baseado nessas caracter√≠sticas, alcan√ßou um desempenho excelente, validando a efic√°cia da abordagem.

Os resultados sugerem que a combina√ß√£o dessas features pode servir como base para sistemas de classifica√ß√£o autom√°tica mais sofisticados. Para o p√∫blico geral, estes achados oferecem indicadores pr√°ticos para a identifica√ß√£o de conte√∫do suspeito. Como pr√≥ximos passos, sugere-se a integra√ß√£o dessas descobertas em modelos mais avan√ßados e a cria√ß√£o de materiais educativos que traduzam esses padr√µes em orienta√ß√µes acess√≠veis.

## Demais anota√ß√µes e refer√™ncias

1.  **MongoDB Atlas e Integra√ß√£o com Python (PyMongo)**
    MongoDB, Inc. (2024). *A Guide to Connect Databricks and MongoDB Atlas using Python API*. CloudThat.
    Dispon√≠vel em: [https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api](https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api)

2.  **Databricks e Processamento de Dados com MongoDB Atlas**
    Raisinghani, A. (2024). *Utilizing PySpark to Connect MongoDB Atlas with Azure Databricks*. MongoDB Developer Center.
    Dispon√≠vel em: [https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo](https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo)

3.  **Documenta√ß√£o Oficial do PyMongo**
    MongoDB, Inc. (2025). *PyMongo Documentation*.
    Dispon√≠vel em: [https://pymongo.readthedocs.io](https://pymongo.readthedocs.io)

4.  **Documenta√ß√£o Oficial do Databricks**
    Databricks, Inc. (2025). *Databricks Documentation*.
    Dispon√≠vel em: [https://docs.databricks.com](https://docs.databricks.com)
